{
 "metadata": {
  "name": "",
  "signature": "sha256:a0647d81daaba3fe8439f9cc52650ab0326e10c42010ba29fa1f5e176c4eda76"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Python Recap Exam\n",
      "\n",
      "This exam is meant to test how fluent or how rusty you are in Python. \n",
      "We do some simple things working with lists, counting things, and doing a bit of basic statistics.\n",
      "You may not remember everything at one. That is no problem, if you can reasonably fast find it back using Python's reference.\n",
      "\n",
      "Also, don't forget the great help that IPython can give you: TAB and ?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Start with running the following code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re,pprint,nltk\n",
      "from __future__ import division\n",
      "from nltk.corpus import reuters \n",
      "# make a corpus of all words in the test files\n",
      "testIDs= [w for w in reuters.fileids() if w.startswith('test')]\n",
      "testWords=reuters.words(testIDs)\n",
      "testWords[:5]\n",
      "\n",
      "\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "[u'ASIAN', u'EXPORTERS', u'FEAR', u'DAMAGE', u'FROM']"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Questions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make the questions. \n",
      "Answer them  in the code block after the question. \n",
      "\n",
      "Reuse variables that you have defined in earlier questions in later questions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "(1) How many words/tokens are there in testWords? And how many unique tokens/words? What is the average frequency of a word?\n",
      "Define a variable for each subquestion.\n",
      "Then print out all variables at once. Use this style for the other exercises as well.\n",
      "So something like:\n",
      "```\n",
      "NumWords = ...\n",
      "NumUnique = ...\n",
      "AvgFreq = ....\n",
      "NumWords, NumUnique, AvgFreq\n",
      "```\n",
      "Or even better with a nicely formatted string."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "NumWords = len(testWords)\n",
      "NumUnique = len(set(testWords))\n",
      "AvgFreq = NumWords/NumUnique\n",
      "\n",
      "NumWords, NumUnique, AvgFreq\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "(467205, 22337, 20.91619286385817)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(2) How many bigrams are there in testWords? How many unique ones? What is the average bigram frequency? Explain the difference of the last two numbers with the numbers in the previous question. \n",
      "Make it easy for yourself. Just use the most \"dumb\" definition of bigram."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigrams = list(nltk.bigrams(testWords))\n",
      "NumBigrams = len(bigrams)\n",
      "UniqueBigrams = len(set(bigrams))\n",
      "BiAvgFreq = NumBigrams/UniqueBigrams\n",
      "\n",
      "print NumBigrams, UniqueBigrams, BiAvgFreq\n",
      "print \"\"\"The difference in the number of unique bigrams can be explained by the number of combinations that is possible. Every word can be\n",
      "with another word, thus creating a larger number. The average frequency of bigrams is follows from that. As there are far more possibilities \n",
      "for bigrams, they are likely to come in smaller frequency.\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "467204 155763 2.99945429916\n",
        "The difference in the number of unique bigrams can be explained by the number of combinations that is possible. Every word can be\n",
        "with another word, thus creating a larger number. The average frequency of bigrams is follows from that. As there are far more possibilities \n",
        "for bigrams, they are likely to come in smaller frequency.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(3)  There are quite some tokens in testWords which are not really \"words\".\n",
      "\n",
      "Use [regular expressions](https://docs.python.org/2/library/re.html) and use the list of english stopwords which can be obtained as follows:\n",
      "\n",
      "```\n",
      "from nltk.corpus import stopwords\n",
      "# test\n",
      "stopwords.words('english')[:20]\n",
      "```\n",
      "\n",
      "Don't display too many digits behind the comma: use the `round()` function to control that.\n",
      "\n",
      "3.1. Create the list of all \"punctuation tokens\" in testWords.\n",
      "\n",
      "3.2. Create the list of all \"stopword tokens\" in testWords. Use NLTK's english stopword list.\n",
      "\n",
      "3.3. Compute the percentage of all tokens in testWords that is a punctuation and the percentage of all tokens in testWords that is a stopword.\n",
      "\n",
      "3.4. How many (as a percentage) of the UNIQUE tokens in testWords is a punctuation? How many a stopword?\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "\n",
      "stopWordsEng = stopwords.words(\"english\")\n",
      "\n",
      "punct = []\n",
      "stopWordsToken = []\n",
      "\n",
      "for word in testWords:\n",
      "    punct += re.findall(r'\\W+', word) # Finds all non-alphanumeric tokens.\n",
      "    if word in stopWordsEng: # Finds all stopwords and filters them into a set.\n",
      "        stopWordsToken.append(word)\n",
      "\n",
      "numTestWords = len(testWords)\n",
      "percentPunc = round((len(punct) /numTestWords), 4) * 100 # Round minimizes the number of decimals behind the comma.\n",
      "percentStop = round((len(stopWordsToken) / numTestWords), 4) * 100\n",
      "\n",
      "print \"The percentage of punctuation tokens in testWords:\", percentPunc, \"%\"\n",
      "print \"The percentage of stopwords in testWords:\", percentStop, \"%\"\n",
      "\n",
      "numUniqueTestWords = len(set(testWords))\n",
      "numUniquePunct = len(set(punct))\n",
      "numUniqueStop = len(set(stopWordsToken))\n",
      "percentUniquePunc = round(numUniquePunct / numUniqueTestWords, 4) * 100\n",
      "percentUniqueStop = round(numUniqueStop / numUniqueTestWords, 4) * 100\n",
      "\n",
      "print \"\\n\"\n",
      "print \"The percentage of punctuation in the unique tokens:\", percentUniquePunc, \"%\"\n",
      "print \"The percentage of stopwords in the unique tokens:\", percentUniqueStop, \"%\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The percentage of punctuation tokens in testWords: 14.82 %\n",
        "The percentage of stopwords in testWords: 22.63 %\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The percentage of punctuation in the unique tokens: 0.32 %\n",
        "The percentage of stopwords in the unique tokens: 0.55 %\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.5 We will now start counting _how often_ words appear in the list `testWords`. Counting is a very important and often used tool. It is _expensive_ as it involves sorting.\n",
      "\n",
      "There are several ways to do counting, and we look at a few of them:\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The number of times the word \"the\" occurs\n",
      "the = [x for x in testWords if x=='the']\n",
      "len(the), len(set(the)), the[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(15048, 1, [u'the', u'the', u'the', u'the', u'the'])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Each list has a count method, which is ideal for counting\n",
      "testWords.count('the')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "15048"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This trick counts all items in one go and yields a dictionary\n",
      "from collections import Counter\n",
      "z = ['blue', 'red', 'blue', 'yellow', 'blue', 'red']\n",
      "Counter(z), Counter(z)['blue']\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(Counter({'blue': 3, 'red': 2, 'yellow': 1}), 3)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# with NLTK we can make a similar datastructure\n",
      "testfd= nltk.FreqDist(testWords)\n",
      "testfd.items()[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[(u'Durapipe', 1),\n",
        " (u'Irving', 17),\n",
        " (u'woods', 1),\n",
        " (u'hanging', 1),\n",
        " (u'HARDIE', 1)]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.5.1 Use `set()` and dict comprehension to create a dict like `testfd` using the `.count()` method\n",
      "\n",
      "3.5.2 You now have 3 ways to make a wordcount dictionary. Use the timing functions to see which one is the fastest.\n",
      "\n",
      "3.5.3 Which percentage of the UNIQUE tokens in testWords is a hapax (i.e. occurs only once in testWords)?\n",
      "\n",
      "3.5.4 Which percentage of the   tokens in testWords is a hapax? \n",
      "\n",
      "3.5.5 Explain why the following test returns True: `len(testfd)==len(set(testWords))`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(4) Count the tokens in testWords. Make an estimate of the following probability: given a string t, if we draw an arbitrary  token from testWords, what is the chance that it equals t?\n",
      "\n",
      "Program it as a function prob(str).\n",
      "Give an example of a high and of a low probability word.\n",
      "\n",
      "Does prob work on every input string?\n",
      "\n",
      "Test that 'the probabilities add up to 1'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "mostlikely = \"\"\n",
      "mostlikelynum = 0\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(5) Suppose we have printed out testWords  using exactly one space between each two tokens. Suppose we have covered a wall with this string. Now you throw a dart missile on this wall. Assume that it always hits exactly one character, which is either a space (inserted by our printing process) or a character in a token.\n",
      "\n",
      "5.1 What is the probability that it hits a space?\n",
      "\n",
      "5.2 Define a function prob(n) which for integer n returns the probability that the missile hits a token of length n.\n",
      "\n",
      "5.3 Nicely print out a table of the form \"n,  prob(n)\" which for each n returns   prob(n). Format it well, and truncate numbers. Bonus points for those who make a plot.\n",
      "\n",
      "5.3.1 Write a good test which indicates that prob(n) works correctly.\n",
      "\n",
      "5.4 What is the probability that it hits a stopword?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "BONUS (if you have time left or got bored)\n",
      "\n",
      "Show that the  words in testWords have a Zipfian distribution. Count the words, order them by their frequency. Plot the log(frequency) times log(index of the word). \n",
      "\n",
      "Use `% matplotlib inline` to display the figure in the notebook.\n",
      "\n",
      "Is it a straight line?\n",
      "\n",
      "Now do the same for the unigrams and the bigrams together in one list. Is the plot \"better\"? What does 'better' mean here?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}